---
title: "A1_U1"
author: "Jhon Alexander Rojas Tavera"
date: "2024-02-13"
output: 
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r , include=FALSE, message=FALSE, echo=FALSE, warning=FALSE}
#devtools::install_github("dgonxalex80/paqueteMODELOS", force = TRUE)

# Instalación y carga de las librerías necesarias (si no están instaladas)
if (!require(tidyverse)) {
  install.packages("tidyverse")
}
if (!require(ggplot2)) {
  install.packages("ggplot2")
}

# Instalar y cargar el paquete 'psych' para cálculos estadísticos
if (!requireNamespace("psych", quietly = TRUE)) {
  install.packages("psych")
}

# Instalar y cargar el paquete 'cluster' si no está instalado
if (!requireNamespace("cluster", quietly = TRUE)) {
  install.packages("cluster")
}

# Carga de librerías
library(paqueteMODELOS)
library(tidyverse)
library(ggplot2)
library(cluster)
library(knitr)
library(naniar)
library(dplyr)
library(psych)
library(tidyr)
```



<h1><b>Informe Evaluación de la oferta inmobiliaria urbana</b></h1> 
<h2>Presentado por Jhon Alexander Rojas Tavera</n></h2> 


<h3>Problema </h3>
<p>
Una empresa inmobiliaria líder en una gran ciudad está buscando comprender en profundidad el mercado de viviendas urbanas para tomar decisiones estratégicas más informadas. La empresa posee una base de datos extensa que contiene información detallada sobre diversas propiedades residenciales disponibles en el mercado. Se requiere realizar un análisis holístico de estos datos para identificar patrones, relaciones y segmentaciones relevantes que permitan mejorar la toma de decisiones en cuanto a la compra, venta y valoración de propiedades.</p>


<h3>Retos:</h3>


El reto principal consisten en realizar un análisis integral y multidimensional de la base de datos para obtener una comprensión del mercado inmobiliario urbano. Se requiere aplicar diversas técnicas de análisis de datos, incluyendo


<ol>
<li>Análisis de Componentes Principales: Reducir la dimensionalidad del conjunto de datos y visualizar la estructura de las variables en componentes principales para identificar características clave que influyen en la variación de precios y oferta del mercado.</li>


<li>Análisis de Conglomerados: Agrupar las propiedades residenciales en segmentos homogéneos con características similares para entender las dinámicas de las ofertas específicas en diferentes partes de la ciudad y en diferentes estratos socio económicos.</li>


<li>Análisis de Correspondencia : Examinar la relación entre las variables categóricas (tipo de vivienda, zona y barrio), para identificar patrones de comportamiento de la oferta en mercado inmobiliario.</li>


<li>Visualización de resultados: Presentar gráficos, mapas y otros recursos visuales para comunicar los hallazgos de manera clara y efectiva a la dirección de la empresa.</li>
</ol>


## Analisis exploratorio de datos

En este primer paso tal como se muestra en el momento de acción en Brightspace, se explora a continuación el conjunto de datos para conocer la dimensión del mismo y sus atributos de forma compacta, cabe destacar que aquí la base vivienda cuenta con 8,322 filas y 13 columnas, dato esencial para reconocer la particularidad de los datos según lo observado en la unidad de analisis multivariado.

```{r, warning=FALSE, echo=FALSE}

data(vivenda)
str(vivienda)
```
En este apartado se puede evidenciar que según la muestra de información el campo piso presenta valores faltantes y estos pueden verse asociados al tipo denominado casa, sin embargo, esta primer inferencia no es del todo cierta toda vez que si existen registros del mismo tipo de vivienda que cuentan con dicha información. 
```{r}
options(tibble.width = Inf)
kable(head(vivienda))
```


En este apartado se pretende conocer el resumen estadístico básico del conjunto de datos, en este se puede observar que las columnas: 	zona,	piso, tipo y barrio son variables categóricas. 
```{r , echo=FALSE}
kable(summary(vivienda))
```

Aquí se desprende un análisis e identificación de valores faltantes o ausentes por lo que se procede a realizar un zoom y evidenciar gráficamente el impacto de los mismo. Se puede observar que en la tabla anterior el resumen estadistico presentaba un sesgo debido que resume que el campo parqueadero era el campo con el mayor volumen de datos ausentes para un total de 1605, sin embargo al revisar los pasos anteriores se detectó que la columna Piso en vez de presentar datos ausentes presentaba un relleno en su diligenciamiento de información con la cadena de texto "NA" por lo que en los pasos siguientes se pretende asegurar esta información.

```{r , echo=FALSE, warning=FALSE}

# Calcular el total de valores faltantes por columna
total_missing <- colSums(is.na(vivienda))

# Mostrar los resultados en una tabla
kable(data.frame(Columna = names(total_missing), Valores_Faltantes = total_missing))
```

Debido que todas las columnas del conjunto de datos presentan valores faltantes, se procede a dimensionar gráficamente la participación de los mismos.

```{r , echo=FALSE}

# Crear el dataframe con los datos
missing_data <- data.frame(Columna = names(total_missing), Valores_Faltantes = total_missing)

# Graficar los valores faltantes
ggplot(missing_data, aes(x = Columna, y = Valores_Faltantes)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = Valores_Faltantes), vjust = -0.5, size = 3) +  # Agregar etiquetas
  labs(title = "Valores Faltantes por Columna", x = "Columna", y = "Cantidad de Valores Faltantes") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


A continuación se grafican a mi criterio las principales visualizacones acerca del negocio inmobiliario presentado: 

Para este primer gráfico se identifica que existen muchos registros en los rangos 167 - 234; 301 - 368 respecto al precio, por lo que para cuantificar dichos inmuebles es necesario en el preprocesamiento excluir los valores NA para tal operación;   


```{r , warning=FALSE, echo=FALSE}

# Gráfico de histograma para la variable 'preciom'
ggplot(vivienda, aes(x = preciom)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  stat_bin(geom = "text", aes(label = paste(round(..xmin..), "-", round(..xmax..))), vjust = -1.5, size = 3, angle = 90) +  # Etiquetas de rango
  labs(title = "Distribución de los precios de las viviendas por rangos",
       x = "Precio",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))  # Rotar etiquetas del eje X para mejor visualización

```


Aquí podemos observar que con los datos ácidos el conjunto de datos revela que las zonas mas representativas con registros de viviendas son la zona sur con una participación de 56,8% y la zona norte con una participación de 20,1% para un gran total de 76,9%, por tanto la acción comercial fuerte se ubica en estas zonas estrategicas de operación.

```{r , warning=FALSE, echo=FALSE}
# Calcular la participación del total de filas por zona
total_rows <- nrow(vivienda)
zona_counts <- table(vivienda$zona)
participacion <- round(zona_counts / total_rows * 100, 2)  # Calcular la participación en porcentaje y redondear a dos decimales

# Crear el gráfico de barras con etiquetas de frecuencia y participación
ggplot(vivienda, aes(x = zona)) +
  geom_bar(fill = rainbow(length(unique(vivienda$zona))), color = "black") +
  stat_count(geom = "text", aes(label = paste(after_stat(count), " (", participacion, "%)")), vjust = -0.5, size = 3, angle = 90) +  # Etiquetas de frecuencia y participación
  labs(title = "Distribución y participación de las viviendas por zona",
       x = "Zona",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas del eje X para mejor visualización

```

En este siguiente grafico la concentración de puntos alrededor de la coordenada (250, 500) indica que hay una gran cantidad de viviendas con un área construida alrededor de 250 unidades y un precio alrededor de 500 unidades. Esto puede  sugerir que hay una tendencia común en el mercado inmobiliario para este tipo de viviendas, donde se establece un precio promedio basado en el área construida.
```{r , warning=FALSE, echo=FALSE}
# Gráfico de dispersión para 'preciom' vs 'areaconst'
ggplot(vivienda, aes(x = areaconst, y = preciom)) +
  geom_point(color = "skyblue") +
  labs(title = "Relación entre el área construida y el precio",
       x = "Área construida",
       y = "Precio")

```

En este se determina que en general, las viviendas clasificadas en el estrato 6 tienen precios más altos en comparación con otras categorías de estratos. Mientras que las viviendas del estrato 5 tienen precios en un rango más bajo en comparación con el estrato 6, pero aún así, relativamente más altos que otros estratos inferiores.
```{r , warning=FALSE, echo=FALSE}

# Gráfico de cajas para 'estrato'
ggplot(vivienda, aes(x = as.factor(estrato), y = preciom, fill = as.factor(estrato))) +
  geom_boxplot() +
  scale_fill_manual(values = rainbow(length(unique(vivienda$estrato)))) +  # Asignar colores diferentes
  labs(title = "Distribución de precios por estrato",
       x = "Estrato",
       y = "Precio" ,
       fill = "Estrato")
```

En los siguientes gráficos se presenta la distribución de tipo de vivienda, en este primero, se observa que si bien existen mas apartamentos que casas en el conjunto de datos, el segundo gráfico nos da cuenta que existe al menor por tipo de vivienda una mayor área construida en las casas.

```{r , warning=FALSE, echo=FALSE}

# Gráfico de barras para 'tipo'
ggplot(vivienda, aes(x = tipo, fill = tipo)) +
  geom_bar(color = "black") +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5, size = 3) +  # Agregar etiquetas de datos
  scale_fill_manual(values = rainbow(length(unique(vivienda$tipo)))) +  # Asignar colores diferentes
  labs(title = "Distribución de las viviendas por tipo",
       x = "Tipo",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas del eje X para mejor visualización

# Gráfico de dispersión para 'areaconst' vs 'tipo'
ggplot(vivienda, aes(x = areaconst, y = tipo, color = tipo)) +
  geom_point() +
  scale_color_manual(values = rainbow(length(unique(vivienda$tipo)))) +  # Asignar colores diferentes
  labs(title = "Relación entre el área construida y el tipo de vivienda",
       x = "Área construida",
       y = "Tipo de vivienda")
```






  
<h2>Preprocesamiento de datos:</n></h2>

A partir de este momento con el conocimiento del conjunto de datos, se procede a la eliminación de la columna ID,longitud y latitud que a mi concepto no aportan valor al informe. De otra parte se da el tratamiento correspondiente a los valores ausentes o faltantes que en el análisis exploratorio de datos impidieron que se analizara la correlación por estar presentes.

```{r  , echo=FALSE}

# Crear una copia del dataframe original sin las columnas ID, longitud y latitud
df_fit <- vivienda %>%
  select(-id, -longitud, -latitud)

# Verificar la estructura del nuevo dataframe
summary(df_fit)

```
```{r  , echo=FALSE}
# Eliminar filas con valores faltantes
df_fit <- drop_na(df_fit)
# Resumen estadístico básico
kable(str(df_fit))
```


## 1. Análisis de Componentes Principales (PCA):

Para efectos de este analisis, se presentan a continuación los  valores de desviación estándar indican la cantidad de variabilidad en los datos explicada por cada componente principal. Además para facilitar este paso se escogieron unicamente las variables numericas, en donde; la proporción de varianza y la proporción acumulativa de varianza indican la cantidad de variabilidad total en los datos explicada por cada componente principal y por las componentes principales anteriores, respectivamente. En este caso:

La primera componente principal (PC1) explica aproximadamente el 59.32% de la varianza total en los datos.
Las dos primeras componentes principales (PC1 y PC2) explican aproximadamente el 79.06% de la varianza total en los datos.
Las tres primeras componentes principales (PC1, PC2 y PC3) explican aproximadamente el 87.12% de la varianza total en los datos.
Las cuatro primeras componentes principales (PC1, PC2, PC3 y PC4) explican aproximadamente el 92.83% de la varianza total en los datos.
Las cinco primeras componentes principales (PC1, PC2, PC3, PC4 y PC5) explican aproximadamente el 96.94% de la varianza total en los datos.
Todas las seis componentes principales explican el 100% de la varianza total en los datos, lo cual es esperado ya que estamos utilizando todas las variables en el análisis.

```{r  , echo=FALSE}


# Seleccionar solo las variables numéricas para el PCA
df_numeric <- df_fit %>%
  select(-c(zona, piso, tipo, barrio)) %>%
  drop_na()  # Eliminar filas con valores faltantes

# Realizar el Análisis de Componentes Principales (PCA)
pca <- prcomp(df_numeric, scale. = TRUE)

# Resumen del PCA
summary(pca)
```
En este caso, el resumen del PCA muestra seis componentes, pero se observa que la mayoría de la varianza se explica con las dos primeras componentes principales (PC1 y PC2), que capturan el 79.06% de la varianza total. Esto sugiere que solo las dos primeros componentes principales se pueden considerar para simplificar el análisis, ya que representan la mayor parte de la variabilidad en los datos.
```{r , include=TRUE,  , echo=FALSE}
# Crear un dataframe con la información del PCA
pca_info <- data.frame(
  Component = paste("PC", 1:6, sep = ""),
  Standard_Deviation = pca$sdev,
  Proportion_of_Variance = pca$sdev^2 / sum(pca$sdev^2),
  Cumulative_Proportion = cumsum(pca$sdev^2 / sum(pca$sdev^2))
)

# Graficar la proporción de varianza explicada por cada componente principal
ggplot(pca_info, aes(x = Component, y = Proportion_of_Variance)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Proporción de Varianza Explicada por Componente Principal",
       x = "Componente Principal",
       y = "Proporción de Varianza") +
  theme_minimal()

# Graficar la varianza acumulada explicada por los primeros n componentes principales
ggplot(pca_info, aes(x = Component, y = Cumulative_Proportion)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(title = "Varianza Acumulada Explicada por Componentes Principales",
       x = "Componente Principal",
       y = "Varianza Acumulada Explicada") +
  theme_minimal()

# Graficar un biplot del PCA
biplot(pca, scale = 0)


```
De acuerdo al material de la asignatura y lo observado en literatura se puede aplicar la "regla del codo" en el análisis de componentes principales, en esta se calculara la varianza explicada por cada componente principal y se trazaría un gráfico para identificar el punto en el que se produce un cambio significativo en la pendiente (el "codo"), en este se observa que la curva se genera para el primer y segun componente para confirmar lo observado anteriormente.
```{r , include=TRUE,  , echo=FALSE}

# Función para identificar el punto de 'codo'
elbow <- function(var_exp) {
  diff_var_exp <- c(0, diff(var_exp))
  elbow_point <- which(diff_var_exp == max(diff_var_exp))
  return(elbow_point)
}

# Calcular la varianza explicada por cada componente principal
var_exp <- pca$sdev^2 / sum(pca$sdev^2)

# Crear un gráfico de la varianza explicada por cada componente principal
plot(var_exp, type = "b", xlab = "Número de componentes principales", ylab = "Varianza explicada",
     main = "Regla del codo para el PCA")
lines(var_exp, type = "l")

# Identificar el punto de 'codo'
elbow_point <- elbow(var_exp)
points(elbow_point, var_exp[elbow_point], col = "red", pch = 16)
text(elbow_point, var_exp[elbow_point], paste("Codo en", elbow_point, "componentes"), pos = 3)

```


## 2. Análisis de Conglomerados (Clustering):
```{r , include=TRUE,  , echo=FALSE}
# Cargar el paquete necesario si no está instalado
if (!requireNamespace("factoextra", quietly = TRUE)) {
  install.packages("factoextra")
}

# Cargar la librería
library(factoextra)

# Seleccionar las variables relevantes para el análisis de conglomerados
df_cluster <- df_fit %>%
  select(preciom, areaconst)  # Solo se seleccionan las variables numéricas relevantes para el análisis

# Realizar el análisis de conglomerados utilizando el algoritmo K-means
kmeans_model <- kmeans(scale(df_cluster), centers = 3)  # Se especifica el número de clusters deseado

# Obtener los resultados del modelo
cluster_centers <- as.data.frame(kmeans_model$centers)  # Centroides de los clusters
cluster_labels <- as.factor(kmeans_model$cluster)       # Etiquetas de los clusters asignadas a cada observación

# Añadir las etiquetas de los clusters al dataframe original
df_cluster_with_labels <- cbind(df_cluster, cluster = cluster_labels)

# Visualizar los centroides de los clusters
print(cluster_centers)

# Visualizar la distribución de las observaciones en los clusters
fviz_cluster(kmeans_model, geom = "point", data = scale(df_cluster))  # Gráfico de dispersión de los clusters

```




Los resultados muestran tres centroides de los clusters identificados por el algoritmo K-means en función de las variables preciom (precio por metro cuadrado) y areaconst (área construida). Los centroides de los clusters se pueden entender como:

Cluster 1: Caracterizado por valores moderadamente bajos tanto en preciom como en areaconst.
Cluster 2: Caracterizado por valores moderadamente altos tanto en preciom como en areaconst.
Cluster 3: Caracterizado por valores relativamente altos tanto en preciom como en areaconst.


## 3.Análisis de Correspondencia:

El análisis de correspondencia múltiple (ACM) realizado revela información importante sobre las relaciones entre las variables categóricas en el conjunto de datos. Las dimensiones principales identificadas muestran la estructura subyacente en los datos y cuánto de la varianza total de los datos explican.

En primer lugar, las dimensiones principales capturan el grado de asociación entre las categorías de las variables. Por ejemplo, la Dimensión 1, con una varianza explicada del 0.711 y que representa el 0.770% de la varianza total, muestra una relación entre el tipo de propiedad (apartamento o casa) y la zona geográfica (centro, norte, oeste, oriente, sur), con valores de contraste significativos.

La Dimensión 2, con una varianza explicada del 0.663 y que representa el 0.718% de la varianza total, revela una asociación diferente, destacando la relación entre la zona geográfica y otras variables categóricas específicas, como "3 de julio", "acopi", y "aguablanca".

La Dimensión 3, con una varianza explicada del 0.658 y que representa el 0.713% de la varianza total, proporciona información adicional sobre la distribución espacial y las características particulares de ciertas zonas en relación con otras variables categóricas.

Además, el análisis individual de las categorías muestra cómo cada una contribuye a las dimensiones principales y su relación con otras categorías. Por ejemplo, la categoría "Casa" se asocia positivamente con la Dimensión 1, mientras que la categoría "Zona Sur" tiene una fuerte relación positiva con la Dimensión 2.

```{r , include=TRUE,  , echo=FALSE}


# Cargar el paquete necesario si no está instalado
if (!requireNamespace("FactoMineR", quietly = TRUE)) {
  install.packages("FactoMineR")
}

# Cargar la librería
library(FactoMineR)

# Seleccionar las variables categóricas relevantes para el análisis de correspondencia
df_corr <- df_fit %>%
  select(tipo, zona, barrio)  # Solo se seleccionan las variables categóricas

# Convertir las variables a factores si es necesario
df_corr$tipo <- as.factor(df_corr$tipo)
df_corr$zona <- as.factor(df_corr$zona)
df_corr$barrio <- as.factor(df_corr$barrio)

# Realizar el análisis de correspondencia múltiple (MCA)
mca <- MCA(df_corr)

# Mostrar los resultados del análisis
summary(mca)


```


<h2>Conclusiones</h2>

Basadas en el análisis realizado, se extraen las siguientes conclusiones clave:

1. Existe una fuerte asociación entre el tamaño de la vivienda, la ubicación y el precio.
2. Se identificaron segmentos de mercado distintos a través del análisis de conglomerados, lo que sugiere la posibilidad de desarrollar estrategias de marketing personalizadas.
3. Las preferencias del mercado varían según la zona geográfica y el barrio, lo que resalta la importancia de adaptar la oferta de viviendas a las necesidades locales.


<h2>Repositorio Github</h2>


<a href="https://github.com/Jartpuro/A1U1_ModsEstadisticos"> Ver código completo</a>