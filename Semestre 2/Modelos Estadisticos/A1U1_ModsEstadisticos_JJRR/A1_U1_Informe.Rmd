---
title: "A1_U1"
author: "Juan José Restrepo Rosero"
date: "2025-01-26"
output: 
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r , include=FALSE, message=FALSE, echo=FALSE, warning=FALSE}
#devtools::install_github("dgonxalex80/paqueteMODELOS", force = TRUE)

# Instalación y carga de las librerías necesarias (si no están instaladas)
if (!require(tidyverse)) {
  install.packages("tidyverse")
}
if (!require(ggplot2)) {
  install.packages("ggplot2")
}

# Instalar y cargar el paquete 'psych' para cálculos estadísticos
if (!requireNamespace("psych", quietly = TRUE)) {
  install.packages("psych")
}

# Instalar y cargar el paquete 'cluster' si no está instalado
if (!requireNamespace("cluster", quietly = TRUE)) {
  install.packages("cluster")
}

# Carga de librerías
library(paqueteMODELOS)
library(tidyverse)
library(ggplot2)
library(cluster)
library(knitr)
library(naniar)
library(dplyr)
library(psych)
library(tidyr)
```



<h1><b>Informe Evaluación de la oferta inmobiliaria urbana</b></h1> 
<h2>Presentado por Juan José Restrepo Rosero</n></h2> 


<h3>Problema </h3>
<p>
Una empresa inmobiliaria líder en una gran ciudad está buscando comprender en profundidad el mercado de viviendas urbanas para tomar decisiones estratégicas más informadas. La empresa posee una base de datos extensa que contiene información detallada sobre diversas propiedades residenciales disponibles en el mercado. Se requiere realizar un análisis holístico de estos datos para identificar patrones, relaciones y segmentaciones relevantes que permitan mejorar la toma de decisiones en cuanto a la compra, venta y valoración de propiedades.</p>


<h3>Retos:</h3>


El reto principal consisten en realizar un análisis integral y multidimensional de la base de datos para obtener una comprensión del mercado inmobiliario urbano. Se requiere aplicar diversas técnicas de análisis de datos, incluyendo


<ol>
<li>Análisis de Componentes Principales: Reducir la dimensionalidad del conjunto de datos y visualizar la estructura de las variables en componentes principales para identificar características clave que influyen en la variación de precios y oferta del mercado.</li>


<li>Análisis de Conglomerados: Agrupar las propiedades residenciales en segmentos homogéneos con características similares para entender las dinámicas de las ofertas específicas en diferentes partes de la ciudad y en diferentes estratos socio económicos.</li>


<li>Análisis de Correspondencia : Examinar la relación entre las variables categóricas (tipo de vivienda, zona y barrio), para identificar patrones de comportamiento de la oferta en mercado inmobiliario.</li>


<li>Visualización de resultados: Presentar gráficos, mapas y otros recursos visuales para comunicar los hallazgos de manera clara y efectiva a la dirección de la empresa.</li>
</ol>


## Analisis exploratorio de datos

En esta etapa inicial, como se presenta durante el momento de *Acción* en Brightspace, se procede a explorar el conjunto de datos para obtener una visión compacta de su dimensión y atributos. Es importante resaltar que la base de datos de vivienda consta de 8,322 filas y 13 columnas, información clave para identificar las características particulares de los datos, tal como se analiza en la unidad de análisis multivariado.

```{r, warning=FALSE, echo=FALSE}

data(vivenda)
str(vivienda)
```
En esta sección, se observa que, según la muestra de datos, el campo "piso" muestra valores ausentes, los cuales parecen estar relacionados con el tipo de vivienda denominado "casa". No obstante, esta primera inferencia no es completamente precisa, ya que existen registros del mismo tipo de vivienda que sí contienen dicha información.
```{r}
options(tibble.width = Inf)
kable(head(vivienda))
```

En esta sección, se busca obtener un resumen estadístico básico del conjunto de datos. En este resumen, se puede identificar que las columnas "zona", "piso", "tipo" y "barrio" corresponden a variables categóricas.
```{r , echo=FALSE}
kable(summary(vivienda))
```

A partir de este análisis, se identifican los valores faltantes o ausentes, y se procede a realizar un enfoque detallado para evidenciar gráficamente su impacto. En la tabla anterior, el resumen estadístico mostraba un sesgo, indicando que el campo "parqueadero" tenía el mayor volumen de datos ausentes, con un total de 1605. Sin embargo, tras revisar los pasos previos, se detectó que la columna "piso" no presentaba valores ausentes, sino que se había rellenado con la cadena de texto "NA". Por lo tanto, en los pasos siguientes se buscará verificar y corregir esta información.

```{r , echo=FALSE, warning=FALSE}

# Calcular el total de valores faltantes por columna
total_missing <- colSums(is.na(vivienda))

# Mostrar los resultados en una tabla
kable(data.frame(Columna = names(total_missing), Valores_Faltantes = total_missing))
```

Dado que todas las columnas del conjunto de datos contienen valores faltantes, se procede a representar gráficamente la proporción de estos valores ausentes en cada una de las columnas.

```{r , echo=FALSE}

# Crear el dataframe con los datos
missing_data <- data.frame(Columna = names(total_missing), Valores_Faltantes = total_missing)

# Graficar los valores faltantes
ggplot(missing_data, aes(x = Columna, y = Valores_Faltantes)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = Valores_Faltantes), vjust = -0.5, size = 3) +  # Agregar etiquetas
  labs(title = "Valores Faltantes por Columna", x = "Columna", y = "Cantidad de Valores Faltantes") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

A continuación, se presentan, según mi criterio, las principales visualizaciones relacionadas con el negocio inmobiliario:

En el primer gráfico, se observa una alta concentración de registros en los rangos de precios 167-234 y 301-368. Para poder cuantificar adecuadamente estos inmuebles, será necesario excluir los valores "NA" durante el preprocesamiento de los datos.




```{r , warning=FALSE, echo=FALSE}

# Gráfico de histograma para la variable 'preciom'
ggplot(vivienda, aes(x = preciom)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  stat_bin(geom = "text", aes(label = paste0(round(..xmin..), " - ", round(..xmax..))), 
           vjust = -1.5, size = 3, angle = 90) +  # Etiquetas de rango simplificadas
  labs(title = "Distribucion de los precios de las viviendas por rangos",  # Título sin caracteres especiales
       x = "Precio",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))  # Rotar etiquetas del eje X

```

En el análisis anterior, es posible observar los datos ácidos, es decir, que se puede notar que las zonas más representativas en cuanto a registros de viviendas son la zona sur, con una participación del 56,8%, y la zona norte, con una participación del 20,1%. Juntas, estas zonas representan un total del 76,9%, lo que indica que la acción comercial más fuerte se concentra en estas áreas estratégicas de operación.

```{r , warning=FALSE, echo=FALSE}

# Calcular la participación del total de filas por zona
total_rows <- nrow(vivienda)
zona_counts <- table(vivienda$zona)
participacion <- round(zona_counts / total_rows * 100, 2)  # Calcular la participación en porcentaje y redondear a dos decimales

# Crear el gráfico de barras con etiquetas de frecuencia y participación
ggplot(vivienda, aes(x = zona, fill = zona)) +
  geom_bar(color = "black") +  # Colorear las barras por zona
  stat_count(geom = "text", aes(label = paste(after_stat(count), " (", participacion, "%)")), vjust = -0.5, size = 3, angle = 90) +  # Etiquetas de frecuencia y participación
  labs(title = "Distribución y participación de las viviendas por zona",
       x = "Zona",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas del eje X para mejor visualización


```


En este gráfico, se puede apreciar que la concentración de puntos cerca de la coordenada (250, 500) sugiere que existe una gran cantidad de viviendas con un área construida alrededor de las 250 unidades y un precio cercano a las 500 unidades. Este patrón podría indicar una tendencia común en el mercado inmobiliario, donde las viviendas con características similares (en términos de área) tienden a tener precios promedio establecidos de manera proporcional. Esto podría reflejar una relación entre el área construida y el precio, que podría ser un factor clave en la determinación del valor de estas propiedades.

```{r , warning=FALSE, echo=FALSE}
# Gráfico de dispersión para 'preciom' vs 'areaconst'
ggplot(vivienda, aes(x = areaconst, y = preciom)) +
  geom_point(color = "blue") +
  labs(title = "Relación entre el área construida y el precio",
       x = "Área construida",
       y = "Precio")

```

En este análisis, se observa que, en general, las viviendas clasificadas en el estrato 6 tienen precios significativamente más altos en comparación con las de otras categorías de estratos. Por otro lado, las viviendas del estrato 5 presentan precios en un rango más bajo en comparación con el estrato 6, pero aún así, sus precios son relativamente más altos que los de los estratos inferiores. Esto sugiere que el estrato 6 es el segmento más caro del mercado, seguido de cerca por el estrato 5, mientras que los estratos más bajos reflejan precios más accesibles.

```{r , warning=FALSE, echo=FALSE}

# Gráfico de cajas para 'estrato'
ggplot(vivienda, aes(x = as.factor(estrato), y = preciom, fill = as.factor(estrato))) +
  geom_boxplot() +
  scale_fill_manual(values = c("blue", "orange", "green", "red", "purple", "yellow")) +  # Colores personalizados
  labs(title = "Distribución de precios por estrato",
       x = "Estrato",
       y = "Precio" ,
       fill = "Estrato")

```

En los siguientes gráficos se muestra la distribución de tipos de vivienda. En el primero, se observa que, aunque hay más apartamentos que casas en el conjunto de datos, el segundo gráfico revela que, al menos por tipo de vivienda, las casas tienen una mayor área construida en comparación con los apartamentos. Esto sugiere que, aunque la cantidad de apartamentos es mayor, las casas, en promedio, tienden a ser más grandes en términos de superficie construida.

```{r , warning=FALSE, echo=FALSE}
# Gráfico de barras para 'tipo'
ggplot(vivienda, aes(x = tipo, fill = tipo)) +
  geom_bar(color = "black") +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5, size = 3) +  # Agregar etiquetas de datos
  scale_fill_manual(values = c("skyblue", "orange")) +  # Colores personalizados para "casa" y "apartamento"
  labs(title = "Distribución de las viviendas por tipo",
       x = "Tipo",
       y = "Frecuencia") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas del eje X para mejor visualización

# Gráfico de dispersión para 'areaconst' vs 'tipo'
ggplot(vivienda, aes(x = areaconst, y = tipo, color = tipo)) +
  geom_point(alpha = 0.6) +  # Añadir transparencia para evitar solapamiento de puntos
  scale_color_manual(values = c("skyblue", "orange")) +  # Colores personalizados para "casa" y "apartamento"
  labs(title = "Relación entre el área construida y el tipo de vivienda",
       x = "Área construida",
       y = "Tipo de vivienda")

```






  
<h2>Preprocesamiento de datos:</n></h2>

A partir de este momento con el conocimiento del conjunto de datos, se procede a la eliminación de la columna ID,longitud y latitud que a mi concepto no aportan valor al informe. De otra parte se da el tratamiento correspondiente a los valores ausentes o faltantes que en el análisis exploratorio de datos impidieron que se analizara la correlación por estar presentes.

```{r  , echo=FALSE}

# Crear una copia del dataframe original sin las columnas ID, longitud y latitud
df_fit <- vivienda %>%
  select(-id, -longitud, -latitud)

# Verificar la estructura del nuevo dataframe
summary(df_fit)

```
```{r  , echo=FALSE}
# Eliminar filas con valores faltantes
df_fit <- drop_na(df_fit)
# Resumen estadístico básico
kable(str(df_fit))
```


## 1. Análisis de Componentes Principales (PCA):

Para efectos de este analisis, se presentan a continuación los  valores de desviación estándar indican la cantidad de variabilidad en los datos explicada por cada componente principal. Además para facilitar este paso se escogieron unicamente las variables numericas, en donde; la proporción de varianza y la proporción acumulativa de varianza indican la cantidad de variabilidad total en los datos explicada por cada componente principal y por las componentes principales anteriores, respectivamente. En este caso:

La primera componente principal (PC1) explica aproximadamente el 59.32% de la varianza total en los datos.
Las dos primeras componentes principales (PC1 y PC2) explican aproximadamente el 79.06% de la varianza total en los datos.
Las tres primeras componentes principales (PC1, PC2 y PC3) explican aproximadamente el 87.12% de la varianza total en los datos.
Las cuatro primeras componentes principales (PC1, PC2, PC3 y PC4) explican aproximadamente el 92.83% de la varianza total en los datos.
Las cinco primeras componentes principales (PC1, PC2, PC3, PC4 y PC5) explican aproximadamente el 96.94% de la varianza total en los datos.
Todas las seis componentes principales explican el 100% de la varianza total en los datos, lo cual es esperado ya que estamos utilizando todas las variables en el análisis.

```{r  , echo=FALSE}


# Seleccionar solo las variables numéricas para el PCA
df_numeric <- df_fit %>%
  select(-c(zona, piso, tipo, barrio)) %>%
  drop_na()  # Eliminar filas con valores faltantes

# Realizar el Análisis de Componentes Principales (PCA)
pca <- prcomp(df_numeric, scale. = TRUE)

# Resumen del PCA
summary(pca)
```
En este caso, el resumen del PCA muestra seis componentes, pero se observa que la mayoría de la varianza se explica con las dos primeras componentes principales (PC1 y PC2), que capturan el 79.06% de la varianza total. Esto sugiere que solo las dos primeros componentes principales se pueden considerar para simplificar el análisis, ya que representan la mayor parte de la variabilidad en los datos.
```{r , include=TRUE,  , echo=FALSE}
# Crear un dataframe con la información del PCA
pca_info <- data.frame(
  Component = paste("PC", 1:6, sep = ""),
  Standard_Deviation = pca$sdev,
  Proportion_of_Variance = pca$sdev^2 / sum(pca$sdev^2),
  Cumulative_Proportion = cumsum(pca$sdev^2 / sum(pca$sdev^2))
)

# Graficar la proporción de varianza explicada por cada componente principal
ggplot(pca_info, aes(x = Component, y = Proportion_of_Variance)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Proporción de Varianza Explicada por Componente Principal",
       x = "Componente Principal",
       y = "Proporción de Varianza") +
  theme_minimal()

# Graficar la varianza acumulada explicada por los primeros n componentes principales
ggplot(pca_info, aes(x = Component, y = Cumulative_Proportion)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(title = "Varianza Acumulada Explicada por Componentes Principales",
       x = "Componente Principal",
       y = "Varianza Acumulada Explicada") +
  theme_minimal()

# Graficar un biplot del PCA
biplot(pca, scale = 0)


```
De acuerdo al material de la asignatura y lo observado en literatura se puede aplicar la "regla del codo" en el análisis de componentes principales, en esta se calculara la varianza explicada por cada componente principal y se trazaría un gráfico para identificar el punto en el que se produce un cambio significativo en la pendiente (el "codo"), en este se observa que la curva se genera para el primer y segun componente para confirmar lo observado anteriormente.
```{r , include=TRUE,  , echo=FALSE}

# Función para identificar el punto de 'codo'
elbow <- function(var_exp) {
  diff_var_exp <- c(0, diff(var_exp))
  elbow_point <- which(diff_var_exp == max(diff_var_exp))
  return(elbow_point)
}

# Calcular la varianza explicada por cada componente principal
var_exp <- pca$sdev^2 / sum(pca$sdev^2)

# Crear un gráfico de la varianza explicada por cada componente principal
plot(var_exp, type = "b", xlab = "Número de componentes principales", ylab = "Varianza explicada",
     main = "Regla del codo para el PCA")
lines(var_exp, type = "l")

# Identificar el punto de 'codo'
elbow_point <- elbow(var_exp)
points(elbow_point, var_exp[elbow_point], col = "red", pch = 16)
text(elbow_point, var_exp[elbow_point], paste("Codo en", elbow_point, "componentes"), pos = 3)

```


## 2. Análisis de Conglomerados (Clustering):
```{r , include=TRUE,  , echo=FALSE}
# Cargar el paquete necesario si no está instalado
if (!requireNamespace("factoextra", quietly = TRUE)) {
  install.packages("factoextra")
}

# Cargar la librería
library(factoextra)

# Seleccionar las variables relevantes para el análisis de conglomerados
df_cluster <- df_fit %>%
  select(preciom, areaconst)  # Solo se seleccionan las variables numéricas relevantes para el análisis

# Realizar el análisis de conglomerados utilizando el algoritmo K-means
kmeans_model <- kmeans(scale(df_cluster), centers = 3)  # Se especifica el número de clusters deseado

# Obtener los resultados del modelo
cluster_centers <- as.data.frame(kmeans_model$centers)  # Centroides de los clusters
cluster_labels <- as.factor(kmeans_model$cluster)       # Etiquetas de los clusters asignadas a cada observación

# Añadir las etiquetas de los clusters al dataframe original
df_cluster_with_labels <- cbind(df_cluster, cluster = cluster_labels)

# Visualizar los centroides de los clusters
print(cluster_centers)

# Visualizar la distribución de las observaciones en los clusters
fviz_cluster(kmeans_model, geom = "point", data = scale(df_cluster))  # Gráfico de dispersión de los clusters

```




Los resultados muestran tres centroides de los clusters identificados por el algoritmo K-means en función de las variables preciom (precio por metro cuadrado) y areaconst (área construida). Los centroides de los clusters se pueden entender como:

Cluster 1: Caracterizado por valores moderadamente bajos tanto en preciom como en areaconst.
Cluster 2: Caracterizado por valores moderadamente altos tanto en preciom como en areaconst.
Cluster 3: Caracterizado por valores relativamente altos tanto en preciom como en areaconst.


## 3.Análisis de Correspondencia:

El análisis de correspondencia múltiple (ACM) realizado revela información importante sobre las relaciones entre las variables categóricas en el conjunto de datos. Las dimensiones principales identificadas muestran la estructura subyacente en los datos y cuánto de la varianza total de los datos explican.

En primer lugar, las dimensiones principales capturan el grado de asociación entre las categorías de las variables. Por ejemplo, la Dimensión 1, con una varianza explicada del 0.711 y que representa el 0.770% de la varianza total, muestra una relación entre el tipo de propiedad (apartamento o casa) y la zona geográfica (centro, norte, oeste, oriente, sur), con valores de contraste significativos.

La Dimensión 2, con una varianza explicada del 0.663 y que representa el 0.718% de la varianza total, revela una asociación diferente, destacando la relación entre la zona geográfica y otras variables categóricas específicas, como "3 de julio", "acopi", y "aguablanca".

La Dimensión 3, con una varianza explicada del 0.658 y que representa el 0.713% de la varianza total, proporciona información adicional sobre la distribución espacial y las características particulares de ciertas zonas en relación con otras variables categóricas.

Además, el análisis individual de las categorías muestra cómo cada una contribuye a las dimensiones principales y su relación con otras categorías. Por ejemplo, la categoría "Casa" se asocia positivamente con la Dimensión 1, mientras que la categoría "Zona Sur" tiene una fuerte relación positiva con la Dimensión 2.

```{r , include=TRUE,  , echo=FALSE}


# Cargar el paquete necesario si no está instalado
if (!requireNamespace("FactoMineR", quietly = TRUE)) {
  install.packages("FactoMineR")
}

# Cargar la librería
library(FactoMineR)

# Seleccionar las variables categóricas relevantes para el análisis de correspondencia
df_corr <- df_fit %>%
  select(tipo, zona, barrio)  # Solo se seleccionan las variables categóricas

# Convertir las variables a factores si es necesario
df_corr$tipo <- as.factor(df_corr$tipo)
df_corr$zona <- as.factor(df_corr$zona)
df_corr$barrio <- as.factor(df_corr$barrio)

# Realizar el análisis de correspondencia múltiple (MCA)
mca <- MCA(df_corr)

# Mostrar los resultados del análisis
summary(mca)


```


<h2>Conclusiones</h2>

Basadas en el análisis realizado, se extraen las siguientes conclusiones clave:

1. Existe una fuerte asociación entre el tamaño de la vivienda, la ubicación y el precio.
2. Se identificaron segmentos de mercado distintos a través del análisis de conglomerados, lo que sugiere la posibilidad de desarrollar estrategias de marketing personalizadas.
3. Las preferencias del mercado varían según la zona geográfica y el barrio, lo que resalta la importancia de adaptar la oferta de viviendas a las necesidades locales.


<h2>Repositorio Github</h2>


<a href="https://github.com/Jartpuro/A1U1_ModsEstadisticos"> Ver código completo</a>