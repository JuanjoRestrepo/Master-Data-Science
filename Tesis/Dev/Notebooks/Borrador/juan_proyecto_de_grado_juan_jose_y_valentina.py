# -*- coding: utf-8 -*-
"""Juan - Proyecto de Grado Juan Jose y Valentina.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OqT11Fa8MCiWdjUIsCgTaKMRg4C_dPQ8

# 1. Configuración Inicial y Verificación de Espacio
"""

# Importar librerías necesarias para el proceso
import os
import pandas as pd
import zipfile
import shutil

# Verificar el espacio disponible en el disco local de Colab
!df -h /content

"""# 2. Descarga del Conjunto de Datos

"""

# Enlace de descarga directo para el archivo ZIP
download_url = 'https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/9xxm58dvs3-2.zip'

# Descargar el archivo ZIP y guardarlo como sicapv2.zip
!wget -O sicapv2.zip $download_url

"""# 3. Descomprimir el Primer Archivo ZIP

"""

# Crear un directorio para los archivos extraídos
!mkdir /content/intermediate_data

# Descomprimir el archivo principal en el directorio intermedio
!unzip -q /content/sicapv2.zip -d /content/intermediate_data/

# Listar los contenidos para verificar
!ls /content/intermediate_data/

"""# 4. Descomprimir el Archivo ZIP Anidado"""

# Ruta al archivo ZIP anidado
nested_zip_path = "/content/intermediate_data/SICAPv2 - Prostate Whole Slide Images with Gleason Grades Annotations/SICAPv2.zip"

# Crear un directorio para el resultado final
!mkdir -p /content/sicapv2_data

# Descomprimir el archivo anidado en el directorio final
!unzip -q "$nested_zip_path" -d /content/sicapv2_data/

# Listar el contenido del directorio final
!ls /content/sicapv2_data/

"""# 5. Limpiar y Organizar el Espacio

"""

# Eliminar el archivo ZIP principal
!rm /content/sicapv2.zip

# Eliminar el directorio intermedio y su contenido de forma recursiva
!rm -r /content/intermediate_data/

# Verificar el espacio y las carpetas restantes
!df -h /content
!ls /content/

"""# 6. Cargar las Anotaciones"""

# Cargar el archivo de anotaciones
df = pd.read_excel('/content/sicapv2_data/SICAPv2/wsi_labels.xlsx')

# Mostrar las primeras filas del dataframe
print(df.head())

df.shape

df.info()

!ls /content/sicapv2_data/SICAPv2/images

!ls /content/sicapv2_data/SICAPv2/masks/

"""# 7. Inspección de máscaras y construcción dataset_manifest.csv

## 1) Configuración inicial
"""

!pip install -q opencv-python-headless tqdm

# Importar librerías
import os, json, re, shutil
from pathlib import Path
import numpy as np, pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import cv2
from collections import defaultdict, Counter


# Rutas por defecto (ajustar si ya tienes los datos)
IMAGES_DIR = '/content/sicapv2_data/SICAPv2/images'
MASKS_DIR  = '/content/sicapv2_data/SICAPv2/masks'
LABELS_XLSX = '/content/sicapv2_data/SICAPv2/wsi_labels.xlsx'

print('Variables definidas. Revisa que las rutas existen antes de ejecutar las celdas posteriores.')

"""## 2) Descarga y extracción (opcional)"""

download_url = 'https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/9xxm58dvs3-2.zip'

if not os.path.exists('/content/sicapv2_data'):
    !wget -O /content/sicapv2.zip $download_url
    !mkdir -p /content/intermediate_data
    !unzip -q /content/sicapv2.zip -d /content/intermediate_data/
    nested_zip_path = "/content/intermediate_data/SICAPv2 - Prostate Whole Slide Images with Gleason Grades Annotations/SICAPv2.zip"
    !mkdir -p /content/sicapv2_data
    !unzip -q "$nested_zip_path" -d /content/sicapv2_data/
    !rm /content/sicapv2.zip
    !rm -r /content/intermediate_data
    print('Descarga y extracción completadas.')
else:
    print('Parece que /content/sicapv2_data ya existe — omito descarga.')

print('Images exists?', os.path.exists(IMAGES_DIR))
print('Masks exists?', os.path.exists(MASKS_DIR))
print('Labels exists?', os.path.exists(LABELS_XLSX))

"""## 3) Cargar anotaciones (wsi_labels.xlsx) y previsualización
Carga la tabla `wsi_labels.xlsx` con las etiquetas a nivel de WSI.

"""

labels_df = pd.read_excel(LABELS_XLSX)
labels_df['slide_id'] = labels_df['slide_id'].astype(str)
slide_to_meta = labels_df.set_index('slide_id').to_dict(orient='index')

print('Slides en labels:', len(labels_df))
display(labels_df.head())

"""| Línea de Resultado      | Resultado Obtenido      | Explicación y Significado                                                                                                                               |
|-------------------------|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|
| Slides en labels: 155   | 155                     | Tamaño del Dataset a Nivel WSI (Muestra Completa): El archivo wsi_labels.xlsx contiene el diagnóstico para 155 diapositivas únicas.                         |
| slide_id                | Ej: 16B000185           | Identificador de Diapositiva: Es la clave única para cada Muestra de Diapositiva Completa (WSI). Se utilizará para correlacionar el diagnóstico de Gleason con los parches extraídos. |
| patient_id              | Ej: 166736045           | Identificador de Paciente: Crucial para la división del dataset (Train/Test/Validation). Debemos asegurar que todos los datos de un mismo paciente se mantengan en un único conjunto para evitar la fuga de datos (data leakage). |
| Gleason_primary         | Ej: 3, 4, 5             | Puntuación de Gleason Primaria: El patrón glandular canceroso más dominante en la diapositiva.                                                            |
| Gleason_secondary       | Ej: 4, 4, 3             | Puntuación de Gleason Secundaria: El segundo patrón glandular canceroso más común.                                                                        |

## 4) Inspección de máscaras y construcción de `dataset_manifest.csv`
La siguiente celda crea un manifest con metadatos por parche y un JSON con paletas de máscara.
"""

def parse_filename(fn):
    basename = os.path.basename(fn)
    m_slide = re.match(r'^([^_]+)_Block', basename)
    slide_id = m_slide.group(1) if m_slide else basename.split('_')[0]
    m = re.search(r'_xini_(\d+)_yini_(\d+)', basename)
    if m:
        x_ini = int(m.group(1)); y_ini = int(m.group(2))
    else:
        x_ini = None; y_ini = None
    return slide_id, x_ini, y_ini

def quick_has_tissue(pil_img, downscale=256, sat_thr=20, val_thr=250, min_frac=0.05):
    arr = np.array(pil_img)
    if arr.ndim == 2: return False
    h, w = arr.shape[:2]
    scale = max(1, int(max(h,w) / downscale))
    small = cv2.resize(arr, (max(1,w//scale), max(1,h//scale)), interpolation=cv2.INTER_AREA)
    hsv = cv2.cvtColor(small, cv2.COLOR_RGB2HSV)
    s = hsv[:,:,1]; v = hsv[:,:,2]
    tissue_mask = (s > sat_thr) & (v < val_thr)
    return float(tissue_mask.mean()) >= min_frac

def inspect_mask(mask_path):
    m = Image.open(mask_path)
    mode = m.mode
    arr = np.array(m)
    info = {'mode': mode}
    if mode == 'P':
        unique_idx = np.unique(arr).tolist()
        palette = m.getpalette()
        colors = {}
        if palette:
            for idx in unique_idx:
                r = palette[3*idx]; g = palette[3*idx+1]; b = palette[3*idx+2]
                colors[str(idx)] = [int(r),int(g),int(b)]
        info.update({'unique_indices': unique_idx, 'palette': colors})
    elif mode == 'L':
        unique_vals = np.unique(arr).tolist()
        info.update({'unique_values': unique_vals})
    elif mode in ('RGB','RGBA'):
        h,w = arr.shape[:2]
        sample = arr
        if h*w > 1000*1000:
            sample = arr[::8,::8,:]
        uniq = np.unique(sample.reshape(-1, sample.shape[2]), axis=0)
        info.update({'unique_rgb': uniq.tolist()})
    else:
        info.update({'note': 'unknown mode'})
    return info

image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.jpg','.jpeg','.png'))])
print('Total image files:', len(image_files))

rows = []
global_palettes = {}
missing_masks = 0
sample_limit = None
it = image_files[:sample_limit] if sample_limit else image_files

for fname in tqdm(it, desc='scanning images'):
    img_path = os.path.join(IMAGES_DIR, fname)
    base, _ = os.path.splitext(fname)
    mask_fname = base + '.png'
    mask_path = os.path.join(MASKS_DIR, mask_fname)
    slide_id, x_ini, y_ini = parse_filename(fname)
    try:
        with Image.open(img_path) as im:
            width, height = im.size
            has_t = quick_has_tissue(im)
    except Exception as e:
        print('Error opening image', img_path, e)
        continue
    if not os.path.exists(mask_path):
        missing_masks += 1
        mask_info = {'exists': False}
    else:
        mask_info = inspect_mask(mask_path); mask_info['exists'] = True
        global_palettes[mask_fname] = mask_info.get('palette', mask_info.get('unique_values', mask_info.get('unique_rgb', None)))
    if slide_id in slide_to_meta:
        meta = slide_to_meta[slide_id]
        patient_id = int(meta.get('patient_id')) if meta.get('patient_id') is not None else None
        gleason_p = int(meta.get('Gleason_primary')) if meta.get('Gleason_primary') is not None else None
        gleason_s = int(meta.get('Gleason_secondary')) if meta.get('Gleason_secondary') is not None else None
    else:
        patient_id = None; gleason_p = None; gleason_s = None
    rows.append({
        'patch_filename': fname,
        'mask_filename': mask_fname,
        'slide_id': slide_id,
        'patient_id': patient_id,
        'x_ini': x_ini,
        'y_ini': y_ini,
        'width': width,
        'height': height,
        'has_tissue': has_t,
        'mask_exists': mask_info['exists'],
        'mask_mode': mask_info.get('mode', None),
        'mask_summary': json.dumps({k:v for k,v in mask_info.items() if k!='mode'}),
        'Gleason_primary': gleason_p,
        'Gleason_secondary': gleason_s
    })

manifest_df = pd.DataFrame(rows)
manifest_csv = '/content/dataset_manifest.csv'
manifest_df.to_csv(manifest_csv, index=False)
with open('/content/mask_palettes_summary.json','w') as f: json.dump(global_palettes,f,indent=2)

print('Manifest saved to', manifest_csv)
print('Mask palettes summary saved to /content/mask_palettes_summary.json')
print(f'Missing masks: {missing_masks} / {len(it)}')
display(manifest_df.head())

"""## 5) Análisis rápido y visualizaciones por etiqueta
Contamos píxeles por etiqueta, parches por etiqueta y mostramos ejemplos (overlay).
"""

from collections import defaultdict, Counter
manifest = pd.read_csv('/content/dataset_manifest.csv')

# Conteo rápido de valores únicos (muestra)
mask_values_counter = Counter()
sample_files = manifest['mask_filename'].tolist()[:2000]
for fn in tqdm(sample_files, desc='Counting unique mask values (sample)'):
    arr = np.array(Image.open(os.path.join(MASKS_DIR, fn)))
    uniq = np.unique(arr)
    mask_values_counter.update(map(int, uniq.tolist()))
print('Unique values (sample):', mask_values_counter)

# Conteo píxeles por etiqueta (todo el dataset)
counts = defaultdict(int)
for mask_fn in tqdm(manifest['mask_filename'].unique(), desc='Counting pixels per label (all masks)'):
    arr = np.array(Image.open(os.path.join(MASKS_DIR, mask_fn)))
    uniq, cnts = np.unique(arr, return_counts=True)
    for u,c in zip(uniq, cnts):
        counts[int(u)] += int(c)
for k,v in sorted(counts.items()):
    print(f'Label {k}: {v} pixels')

# Parches que contienen cada etiqueta
patch_counts = defaultdict(int)
for idx, row in tqdm(manifest.iterrows(), total=len(manifest), desc='Counting patches per label'):
    p = row['mask_filename']
    arr = np.array(Image.open(os.path.join(MASKS_DIR, p)))
    uniq = np.unique(arr)
    for u in uniq:
        patch_counts[int(u)] += 1
print('Patches containing label (counts):', dict(patch_counts))

# Funciones de overlay y ejemplo por etiqueta
def overlay(image, mask, label_val, color=(255,165,0), alpha=0.5):
    img = np.array(image).astype(np.uint8)
    m = (np.array(mask)==label_val)
    ov = img.copy()
    ov[m] = (ov[m].astype(np.float32)*(1-alpha) + np.array(color).astype(np.float32)*alpha).astype(np.uint8)
    return ov

def show_examples_for_label(label_to_inspect, n_examples=4):
    examples = []
    for fn in manifest['patch_filename'].tolist():
        mask_fn = fn.replace('.jpg','.png')
        mask_path = os.path.join(MASKS_DIR, mask_fn)
        if not os.path.exists(mask_path): continue
        arr = np.array(Image.open(mask_path))
        if label_to_inspect in np.unique(arr):
            examples.append((fn, mask_fn))
        if len(examples) >= n_examples: break
    if len(examples)==0:
        print(f'No examples found for label {label_to_inspect}'); return
    fig, axs = plt.subplots(2, len(examples), figsize=(4*len(examples), 6))
    for i,(imgfn,maskfn) in enumerate(examples):
        img = Image.open(os.path.join(IMAGES_DIR, imgfn)).convert('RGB')
        mask = Image.open(os.path.join(MASKS_DIR, maskfn))
        axs[0,i].imshow(img); axs[0,i].axis('off'); axs[0,i].set_title(imgfn.split('_')[0])
        ov = overlay(img, mask, label_to_inspect, color=(255,165,0), alpha=0.6)
        axs[1,i].imshow(ov); axs[1,i].axis('off'); axs[1,i].set_title(f'Overlay label {label_to_inspect}')
    plt.tight_layout(); plt.show()

show_examples_for_label(4, n_examples=4)
show_examples_for_label(3, n_examples=4)
show_examples_for_label(5, n_examples=4)

"""## 6) Correlación slide ↔ máscaras (confirmación del mapeo de etiquetas)
La celda agrupa píxeles de máscaras por slide y compara la etiqueta dominante con `Gleason_primary`.

"""

labels_df = pd.read_excel(LABELS_XLSX); labels_df['slide_id'] = labels_df['slide_id'].astype(str)

slide_counts = defaultdict(Counter)
mask_files = sorted([f for f in os.listdir(MASKS_DIR) if f.lower().endswith('.png')])
for mf in tqdm(mask_files, desc='Procesando máscaras por slide'):
    slide = mf.split('_')[0]
    arr = np.array(Image.open(os.path.join(MASKS_DIR, mf)))
    uniq, cnts = np.unique(arr, return_counts=True)
    for u,c in zip(uniq, cnts):
        slide_counts[slide][int(u)] += int(c)

rows = []
for slide, counter in slide_counts.items():
    total_pixels = sum(counter.values())
    sorted_items = sorted(counter.items(), key=lambda x: x[1], reverse=True)
    dominant = sorted_items[0][0]
    if dominant == 0:
        nonzero = [(k,v) for k,v in sorted_items if k!=0]
        dominant_nonzero = nonzero[0][0] if len(nonzero)>0 else 0
    else:
        dominant_nonzero = dominant
    rows.append({'slide_id': slide, 'dominant_mask_label_pixels': int(dominant_nonzero), 'counts_dict': dict(counter), 'total_pixels': int(total_pixels)})

slide_mask_summary = pd.DataFrame(rows)
merged = labels_df.merge(slide_mask_summary, on='slide_id', how='left')
merged['match_primary'] = merged['dominant_mask_label_pixels'] == merged['Gleason_primary']

print('Número de slides:', len(merged))
print('Slides donde label dominante de máscara == Gleason_primary:', int(merged['match_primary'].sum()))
print('Proporción match:', float(merged['match_primary'].mean()))
display(merged[['slide_id','Gleason_primary','Gleason_secondary','dominant_mask_label_pixels']].head(10))

merged.to_csv('/content/slide_mask_vs_wsi_labels.csv', index=False)
print('Saved /content/slide_mask_vs_wsi_labels.csv')





































# Guardar resumen
merged.to_csv('/content/slide_mask_vs_wsi_labels.csv', index=False)
print("Saved /content/slide_mask_vs_wsi_labels.csv")

















# Convierte la máscara a un array de numpy para poder visualizarla
import numpy as np
mask_array = np.array(mask)

# Muestra el tamaño de las imágenes cargadas para verificación
print(f'Tamaño de la imagen: {image.size}')
print(f'Forma de la máscara: {mask_array.shape}')

fig, ax = plt.subplots(1, 2, figsize=(12, 6))

# Visualizar la imagen original
ax[0].imshow(image)
ax[0].set_title('Parche de Imagen')
ax[0].axis('off')

# Visualizar la máscara de anotación. Usamos un mapa de colores para las diferentes etiquetas.
ax[1].imshow(mask_array, cmap='jet')
ax[1].set_title('Máscara de Anotación')
ax[1].axis('off')

plt.show()