@article{10.1093/bioinformatics/btaf024,
    author = {Mao, Jinyang and Xu, Junlin and Tang, Xianfang and Liu, Yongjin and Zhao, Heaven and Tian, Geng and Yang, Jialiang},
    title = {CAMIL: channel attention-based multiple instance learning for whole slide image classification},
    journal = {Bioinformatics},
    volume = {41},
    number = {2},
    pages = {btaf024},
    year = {2025},
    month = {01},
    abstract = {The classification task based on whole-slide images (WSIs) is a classic problem in computational pathology. Multiple instance learning (MIL) provides a robust framework for analyzing whole slide images with slide-level labels at gigapixel resolution. However, existing MIL models typically focus on modeling the relationships between instances while neglecting the variability across the channel dimensions of instances, which prevents the model from fully capturing critical information in the channel dimension.To address this issue, we propose a plug-and-play module called Multi-scale Channel Attention Block (MCAB), which models the interdependencies between channels by leveraging local features with different receptive fields. By alternately stacking four layers of Transformer and MCAB, we designed a channel attention-based MIL model (CAMIL) capable of simultaneously modeling both inter-instance relationships and intra-channel dependencies. To verify the performance of the proposed CAMIL in classification tasks, several comprehensive experiments were conducted across three datasets: Camelyon16, TCGA-NSCLC, and TCGA-RCC. Empirical results demonstrate that, whether the feature extractor is pretrained on natural images or on WSIs, our CAMIL surpasses current state-of-the-art MIL models across multiple evaluation metrics.All implementation code is available at https://github.com/maojy0914/CAMIL.},
    issn = {1367-4811},
    doi = {10.1093/bioinformatics/btaf024},
    url = {https://doi.org/10.1093/bioinformatics/btaf024},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/41/2/btaf024/61461331/btaf024.pdf},
}



