% ======================
% DISEÑO DEL PIPELINE
% ======================

\section{Diseño del Pipeline Experimental}

Este capítulo describe de manera detallada el diseño del sistema de clasificación de WSIs mediante Aprendizaje de Instancias Múltiples (MIL). El objetivo es presentar un flujo de procesamiento de datos, extracción de características y modelado que permita una evaluación reproducible del problema médico de clasificación binaria de tejido prostático.

El diseño sigue una metodología incremental basada en Sprints, la cual facilita la organización del desarrollo, la gestión de riesgos y la trazabilidad entre los objetivos del proyecto y la implementación computacional.

\subsection{Sprint 0: Infraestructura, Entorno y Reproducibilidad}

El propósito de este Sprint fue establecer un entorno de desarrollo robusto, escalable y reproducible, preparado para procesar imágenes de resolución gigapíxel sin comprometer la consistencia de los resultados.

\subsubsection{Infraestructura Computacional}

Se configuró un entorno de ejecución basado en instancias con aceleración por GPU (p. ej., NVIDIA T4/V100) para cumplir con los requerimientos computacionales del procesamiento de WSIs. La compatibilidad con CUDA se verificó mediante pruebas de ejecución en PyTorch \cite{paszke2019pytorch}.

\subsubsection{Gestión de Dependencias}

Se instaló el conjunto de librerías necesarias para manipulación de imágenes médicas y machine learning:

\begin{itemize}
    \item \textbf{openslide-python:} Lectura eficiente de pirámides de imágenes WSI sin saturar la memoria principal.
    \item \textbf{Albumentations:} Generación de transformaciones de datos para aumentación durante entrenamiento.
    \item \textbf{OpenCV / scikit-image:} Procesamiento de imágenes y filtrado de contenido útil.
\end{itemize}

\subsubsection{Reproducibilidad Científica}

Se estableció un protocolo de reproducibilidad a nivel de código y entrenamiento con el fijado de una semilla global:

\begin{itemize}
    \item Función de fijación de semilla (\texttt{set\_seed(42)}) para controlar la aleatoriedad en \texttt{numpy}, \texttt{random} y \texttt{torch}.
    \item Uso de entornos virtuales y definición explícita de versiones de librerías para garantizar reproducibilidad completa de resultados.
\end{itemize}

\subsection{Sprint 1: Preprocesamiento y Refinamiento de Datos}

El objetivo de este Sprint fue transformar los datos crudos (WSIs + anotaciones) en un conjunto de tensores limpios, coherentes y libres de inconsistencias, listos para extracción de características y modelado.

\subsubsection{Ajuste de Etiquetado Binario}

Se detectó ambigüedad en la lógica original de lectura de etiquetas desde archivos Excel de particiones. Para resolverlo:

\begin{itemize}
    \item \textbf{Clase 0 (Negativo):} WSIs etiquetadas como 'NC' (No Cancer).
    \item \textbf{Clase 1 (Positivo):} WSIs con Gleason Score $\ge 6$ (G3, G4, G5), acorde con definiciones clínicas \cite{epstein2016gleason, SILVARODRIGUEZ2020105637}.
\end{itemize}

Esta binarización elimina ruido de clases intermedias mal etiquetadas y permite que la definición de la verdad terreno (ground truth) sea consistente para el entrenamiento y la evaluación.

\subsubsection{Filtrado de Tejido Relevante}

Debido al gran tamaño y variabilidad de las WSI, se implementó un enfoque de segmentación basado en umbrales de color:

\begin{itemize}
    \item \textbf{Espacio de Color HSV:} Se calcula una máscara de saturación ($S>0.05$) para separar tejido de fondo.
    \item \textbf{Umbral de Descarte:} Un parche se retiene sólo si contiene $\ge 50\%$ de tejido útil, reduciendo la inclusión de parches vacíos o artefactos.
\end{itemize}

Este filtrado optimiza el entrenamiento al garantizar que sólo parches relevantes sean procesados en etapas posteriores.

\subsection{Sprint 2: Ingeniería de Características}

Este Sprint se centró en la reducción de dimensionalidad y la representación de cada parche mediante vectores numéricos densos (embeddings), evitando la fuga de información entre conjuntos.

\subsubsection{Extracción de Características (Feature Extraction)}

Se empleó un modelo de referencia pre-entrenado para obtener representaciones de cada parche:

\begin{itemize}
    \item \textbf{Backbone:} ResNet50 pre-entrenado en ImageNet, truncado eliminando la última capa totalmente conectada.
    \item \textbf{Entrada:} Tensores de dimensión $(3, 512, 512)$.
    \item \textbf{Salida:} Vectores de características de dimensión $(2048)$ por parche.
\end{itemize}

Este enfoque de transfer learning facilita la captura de patrones relevantes sin requerir entrenamiento desde cero \cite{Litjens2017Survey}.

\subsubsection{Prevención de Fuga de Datos (Group-aware Split)}

Para evitar que parches del mismo paciente se distribuyan entre conjuntos de entrenamiento y prueba, se empleó un esquema de validación estratificada por paciente:

\begin{itemize}
    \item Se usó \textbf{GroupKFold} para generar particiones donde todos los parches de un mismo patient\_id permanecen en el mismo fold.
    \item Esto garantiza una evaluación honesta y clínicamente válida del modelo.
\end{itemize}

\subsubsection{Optimización de Almacenamiento}

Para mejorar la eficiencia computacional:

\begin{itemize}
    \item Se serializaron los embeddings en formatos binarios (.npy, .pt) para acelerar la carga durante entrenamiento y validación.
    \item Esto evita repetidas decodificaciones de imágenes en disco durante cada ciclo de entrenamiento.
\end{itemize}

\subsection{Sprint 3: Modelado MIL y Validación}

Este Sprint corresponde al núcleo del pipeline: la definición del modelo MIL basado en atención y su entrenamiento riguroso.

\subsubsection{Arquitectura de Atención (Gated Attention MIL)}

Se implementó una variante de MIL con atención que:

\begin{itemize}
    \item Procesa bolsas de instancias de tamaño variable.
    \item Asigna pesos de importancia a cada parche.
    \item Facilita interpretabilidad al evidenciar qué parches son más determinantes para la predicción final \cite{ilse2018attention}.
\end{itemize}

La elección de un mecanismo de atención específico responde a la necesidad de interpretabilidad clínica y coherencia con la supervisión débil.

\subsubsection{Entrenamiento y Validación}

\begin{itemize}
    \item Se entrenó el modelo bajo una estrategia de validación cruzada estratificada por paciente (GroupKFold).
    \item La evaluación se realizó a nivel de WSI/bag, utilizando métricas coherentes con lo definido en el Marco Teórico.
\end{itemize}

\subsection{Sprint 4: Interpretación y Mapas de Atención}

La generación de mapas de atención permite:

\begin{itemize}
    \item Identificar regiones de tejido que más aportan a la decisión.
    \item Relacionar las predicciones del modelo con hallazgos clínicamente relevantes.
    \item Validar la interpretabilidad del modelo en bases de datos reales, como SICAPv2.
\end{itemize}

La interpretación de estos mapas se complementa con análisis cuantitativos y visuales presentados en el capítulo de Resultados y Análisis.

\subsection{Sprint 5: Puesta a Punto y Ajuste Final}

Este Sprint se dedicó a:

\begin{itemize}
    \item Ajuste de hiperparámetros mediante búsqueda estructurada.
    \item Evaluación del impacto de preprocesamientos alternativos.
    \item Validación con diferentes particiones de grupos para confirmar robustez de desempeño.
\end{itemize}

\section{Resumen del Diseño del Pipeline}

Este pipeline combina una ingeniería de características cuidadosamente diseñada y un modelo MIL con atención interpretativa. La estrategia de validación, la prevención de fuga de datos y la serialización de embeddings aseguran resultados reproducibles y clínicamente relevantes.

\subsection{Matriz de trazabilidad entre objetivos y requisitos}

Con el fin de garantizar la coherencia entre los objetivos específicos del proyecto y su implementación técnica, se construyó una matriz de trazabilidad que relaciona cada objetivo con los requisitos funcionales correspondientes y el componente del pipeline en el que estos son abordados. Esta matriz permite verificar que todas las decisiones metodológicas y de diseño experimental están directamente alineadas con los objetivos planteados.

\begin{table}[h!]
    \centering
    \caption{Matriz de trazabilidad entre objetivos específicos, requisitos funcionales y componentes del pipeline}
    \label{tab:matriz_trazabilidad}
    \begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|}
        \hline
        \textbf{Objetivo Específico} & \textbf{Requisito Funcional} & \textbf{Componente del Pipeline} \\
        \hline
        OE1: Preprocesamiento y estructuración de datos. & RF-01, RF-02, RF-03 & Sprint 0 y Sprint 1 \\
        \hline
        OE2: Diseño de modelos de aprendizaje profundo. & RF-04, RF-05, RF-06 & Sprint 2 y Sprint 3 \\
        \hline
        OE3: Validación y evaluación diagnóstica. & RF-07 & Sprint 4 \\
        \hline
    \end{tabular}
\end{table}
